# This is a basic workflow to help you get started with Actions

name: Scrape

# Controls when the workflow will run
on:
  schedule:
    - cron: "*/120 * * * *" # every 120 minutes (so, every 2 hours)
  workflow_dispatch:
  # Triggers the workflow on push or pull request events but only for the main branch
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]

  # Allows you to run this workflow manually from the Actions tab
  workflow_dispatch:

# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  # This workflow contains a single job called "scrape"
  scrape:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest

    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      # Checks-out your repository under $GITHUB_WORKSPACE, so your job can access it
      - uses: actions/checkout@v2
      - name: Install pipenv
        run: pipx install pipenv
      - uses: actions/setup-python@v2
        with:
            python-version: '3.9'
            cache: 'pipenv'
      - run: pipenv install --python `which python`

      # Step: install requirments on the cloud computer that has
      # cloned your repo.
      - name: Install requirements
        run: |
          echo python -m pip install requests
          echo python -m pip install sqlite_utils

      # Step: run the python script
      - name: Run script to scrape data
        run: python get_all_data.py


      # Runs a single command using the runners shell
      - name: Run a one-line script
        run: echo Hello, world!

      # Runs a set of commands using the runners shell
      - name: Run a multi-line script
        run: |
          echo Add other actions to build,
          echo test, and deploy your project.
